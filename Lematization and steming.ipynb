{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Lab 1 - 27 Aug 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab Exercises:\n",
    "1. Write a program to tokenize text\n",
    "2. Write a program to count word frequency and to remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'am',\n",
       " 'Milan',\n",
       " 'Jasani',\n",
       " '.',\n",
       " 'I',\n",
       " 'am',\n",
       " 'pursuing',\n",
       " 'data',\n",
       " 'science',\n",
       " 'from',\n",
       " 'christ',\n",
       " 'university',\n",
       " '.',\n",
       " 'Hey',\n",
       " ',',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk.corpus\n",
    "text = \"I am Milan Jasani. I am pursuing data science from christ university. Hey, How are you?\"\n",
    "from nltk.tokenize import word_tokenize\n",
    "token = word_tokenize(text)\n",
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Frequency distinct to the token\n",
    "### import freqDist library from nltk and passing token into freqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'I': 2, 'am': 2, '.': 2, 'Milan': 1, 'Jasani': 1, 'pursuing': 1, 'data': 1, 'science': 1, 'from': 1, 'christ': 1, ...})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fqlist = FreqDist(token)\n",
    "fqlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To find the frequency of top 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = fqlist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 2),\n",
       " ('am', 2),\n",
       " ('.', 2),\n",
       " ('Milan', 1),\n",
       " ('Jasani', 1),\n",
       " ('pursuing', 1),\n",
       " ('data', 1),\n",
       " ('science', 1),\n",
       " ('from', 1),\n",
       " ('christ', 1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing posterstemmar from nltk library\n",
    "### checking for the word 'writting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wait'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pst = PorterStemmer()\n",
    "pst.stem(\"Waiting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'danc'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"Dancing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'give'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pst.stem(\"Giving\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for the list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait\n",
      "wait\n",
      "wait\n"
     ]
    }
   ],
   "source": [
    "for i in [\"Waiting\",\"Waited\",\"Waits\"]:\n",
    "    print(pst.stem(i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing lancasterstemmer from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "giving:giv\n",
      "given:giv\n",
      "given:giv\n",
      "gives:giv\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import LancasterStemmer\n",
    "lst = LancasterStemmer()\n",
    "for i in [\"giving\",\"given\",\"given\",\"gives\"]:\n",
    "    print(i+\":\"+lst.stem(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "- **For example, lemmatization would correctly identify the base form of ‘caring’ to ‘care’. whereas, stemming would cutoff the ‘ing’ part and convert it to a car.Lemmatization can be implemented in python by using Wordnet Lemmatizer, Spacy Lemmatizer, TextBlob, Stanford CoreNLP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing lemmatizer library from nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rocks : rock\n",
      "Corpora : corpus\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wlem = WordNetLemmatizer()\n",
    "print(\"rocks :\", wlem.lemmatize(\"rocks\"))\n",
    "print(\"Corpora :\",wlem.lemmatize(\"corpora\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop Words\n",
    "- **Stop words” are the most common words in a language like “the”, “a”, “at”, “for”, “above”, “on”, “is”, “all”. These words do not provide any meaning and are usually removed from texts. We can remove these stop words using nltk library.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing stopwords from nltk library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cristiano', 'ronaldo', 'was', 'born', 'on', 'february', '5', ',', '1985', ',', 'in', 'funchal', ',', 'madeira', ',', 'portugal', '.']\n",
      "['cristiano', 'ronaldo', 'born', 'february', '5', ',', '1985', ',', 'funchal', ',', 'madeira', ',', 'portugal', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "a = set(stopwords.words(\"english\"))\n",
    "text = \"Cristiano Ronaldo was born on February 5, 1985, in Funchal, Madeira, Portugal.\"\n",
    "text_1 = word_tokenize(text.lower())\n",
    "print(text_1)\n",
    "stopwords = [x for x in text_1 if x not in a]\n",
    "print(stopwords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
